[
  {
    "round": 1,
    "plan_steps": 1,
    "code_length": 2239,
    "code": "# Helper functions for robust data processing\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        return float(v)\n    return float(value)\n\ndef safe_get(df, column, default=None):\n    \"\"\"Safely get column from DataFrame, return default if not exists.\"\"\"\n    if isinstance(df, dict):\n        return df.get(column, default)\n    elif hasattr(df, 'columns') and column in df.columns:\n        return df[column]\n    return default\n\ndef is_not_empty(array):\n    \"\"\"Check if array/list is not empty. Handles numpy arrays safely.\"\"\"\n    if array is None:\n        return False\n    if hasattr(array, 'size'):  # numpy array\n        return array.size > 0\n    try:\n        return len(array) > 0\n    except TypeError:\n        return False\n\ndef safe_index(array, idx, default=None):\n    \"\"\"Safely get array element at index, return default if out of bounds.\"\"\"\n    try:\n        if 0 <= idx < len(array):\n            return array[idx]\n        return default\n    except (IndexError, TypeError, AttributeError):\n        return default\n\n\nimport pandas as pd\n\n# Load the payments.csv file\ndf_payments = pd.read_csv('/output/chunk4/data/context/payments.csv')\n\n# Filter the data for 'Belles_cookbook_store' and year 2023\nfiltered_transactions = df_payments[\n    (df_payments['merchant'] == 'Belles_cookbook_store') & \n    (df_payments['year'] == 2023)\n]\n\n# Print the shape to verify the filtering\nprint(f\"Total rows loaded: {len(df_payments)}\")\nprint(f\"Rows after filtering for Belles_cookbook_store in 2023: {len(filtered_transactions)}\")\n\n# Display the first few rows of the filtered dataframe\nprint(filtered_transactions.head())",
    "execution_output": "Total rows loaded: 138236\nRows after filtering for Belles_cookbook_store in 2023: 13848\n    psp_reference               merchant  ... aci  acquirer_country\n2     31114608278  Belles_cookbook_store  ...   F                US\n10    11539582857  Belles_cookbook_store  ...   F                US\n18    16900553593  Belles_cookbook_store  ...   G                US\n23    79488939497  Belles_cookbook_store  ...   D                US\n26    27927426581  Belles_cookbook_store  ...   G                US\n\n[5 rows x 21 columns]\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.1,
    "plan_snapshot": [
      "Load the `payments.csv` file into a dataframe and filter the data to include only transactions where the `merchant` column is 'Belles_cookbook_store' and the `year` column is 2023."
    ]
  },
  {
    "round": 2,
    "plan_steps": 2,
    "code_length": 9495,
    "code": "import pandas as pd\nimport json\nimport numpy as np\n\n# ==========================================\n# HELPER FUNCTIONS\n# ==========================================\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if pd.isna(value) or value is None:\n        return 0.0\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean for coercion, but parsing logic handles ranges separately\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        try:\n            return float(v)\n        except ValueError:\n            return 0.0\n    return float(value)\n\ndef parse_range_check(value, range_str):\n    \"\"\"\n    Checks if a numeric value falls within a range string.\n    Range strings can be: '100k-1m', '>5', '<3', '7.7%-8.3%', 'immediate', 'manual'\n    \"\"\"\n    if range_str is None:\n        return True\n        \n    # Handle string literals (e.g., 'immediate', 'manual')\n    if isinstance(range_str, str) and not any(c.isdigit() for c in range_str):\n        return str(value) == range_str\n\n    # Normalize value\n    val = float(value)\n    \n    # Normalize range string\n    s = str(range_str).lower().replace(',', '').replace('%', '')\n    \n    # Handle k/m suffixes\n    def parse_num(n_str):\n        n_str = n_str.strip()\n        mult = 1\n        if 'k' in n_str:\n            mult = 1000\n            n_str = n_str.replace('k', '')\n        elif 'm' in n_str:\n            mult = 1000000\n            n_str = n_str.replace('m', '')\n        return float(n_str) * mult\n\n    try:\n        if '-' in s:\n            low, high = s.split('-')\n            # Check if it's percentage range (already stripped %)\n            # If the input value is a ratio (0-1) and range was %, we need to align.\n            # Assuming input 'value' for fraud is a ratio (e.g., 0.08), and range was '7.7-8.3' (now 7.7-8.3).\n            # We should convert the range numbers to ratio if they look like percentages? \n            # Actually, let's assume the caller handles unit consistency. \n            # For fraud: input 0.08, range \"8%\" -> parse_num(\"8\")=8. Mismatch.\n            # Let's handle % specifically in the caller or here.\n            # Better approach: The caller passes raw strings.\n            \n            # Re-parsing with specific logic for this dataset's known formats\n            l = parse_num(low)\n            h = parse_num(high)\n            \n            # Heuristic: if range is 0-100 and value is 0-1, scale value? \n            # Or if range string had '%', scale range?\n            if '%' in str(range_str):\n                l /= 100\n                h /= 100\n            \n            return l <= val <= h\n            \n        if '>' in s:\n            limit = parse_num(s.replace('>', ''))\n            if '%' in str(range_str): limit /= 100\n            return val > limit\n            \n        if '<' in s:\n            limit = parse_num(s.replace('<', ''))\n            if '%' in str(range_str): limit /= 100\n            return val < limit\n            \n        # Exact match numeric\n        target = parse_num(s)\n        if '%' in str(range_str): target /= 100\n        return val == target\n        \n    except Exception as e:\n        # Fallback for non-numeric matching\n        return str(value) == str(range_str)\n\ndef match_fee_rule(tx_context, rule):\n    \"\"\"\n    Matches a transaction context against a fee rule.\n    tx_context must contain:\n    - card_scheme, account_type, merchant_category_code, is_credit, aci, \n    - intracountry, capture_delay, monthly_volume, monthly_fraud_level\n    \"\"\"\n    # 1. Card Scheme (Exact match)\n    if rule.get('card_scheme') and rule['card_scheme'] != tx_context['card_scheme']:\n        return False\n\n    # 2. Account Type (List match)\n    if rule.get('account_type'):\n        if tx_context['account_type'] not in rule['account_type']:\n            return False\n\n    # 3. Merchant Category Code (List match)\n    if rule.get('merchant_category_code'):\n        if tx_context['merchant_category_code'] not in rule['merchant_category_code']:\n            return False\n\n    # 4. Is Credit (Boolean match)\n    if rule.get('is_credit') is not None:\n        if rule['is_credit'] != tx_context['is_credit']:\n            return False\n\n    # 5. ACI (List match)\n    if rule.get('aci'):\n        if tx_context['aci'] not in rule['aci']:\n            return False\n\n    # 6. Intracountry (Boolean match)\n    if rule.get('intracountry') is not None:\n        # Intracountry in rule is boolean, tx_context['intracountry'] is boolean\n        # However, sometimes rule uses 0.0/1.0 for boolean in JSON?\n        # The schema says boolean or null.\n        rule_intra = rule['intracountry']\n        # Handle case where json has 0.0 for False\n        if isinstance(rule_intra, float):\n            rule_intra = bool(rule_intra)\n        if rule_intra != tx_context['intracountry']:\n            return False\n\n    # 7. Capture Delay (Range/String match)\n    if rule.get('capture_delay'):\n        # capture_delay in merchant data is string (e.g. \"1\", \"manual\")\n        # rule is string (e.g. \"<3\", \"manual\")\n        if not parse_range_check(tx_context['capture_delay'], rule['capture_delay']):\n            return False\n\n    # 8. Monthly Volume (Range match)\n    if rule.get('monthly_volume'):\n        if not parse_range_check(tx_context['monthly_volume'], rule['monthly_volume']):\n            return False\n\n    # 9. Monthly Fraud Level (Range match)\n    if rule.get('monthly_fraud_level'):\n        if not parse_range_check(tx_context['monthly_fraud_level'], rule['monthly_fraud_level']):\n            return False\n\n    return True\n\ndef calculate_fee(amount, rule):\n    \"\"\"Calculates fee based on fixed amount and rate.\"\"\"\n    fixed = rule.get('fixed_amount', 0.0)\n    rate = rule.get('rate', 0.0)\n    # Formula: fixed + (rate * amount / 10000)\n    return fixed + (rate * amount / 10000.0)\n\n# ==========================================\n# MAIN LOGIC\n# ==========================================\n\n# 1. Load Data\nbase_path = '/output/chunk4/data/context/'\ndf_payments = pd.read_csv(base_path + 'payments.csv')\nwith open(base_path + 'fees.json', 'r') as f:\n    fees_data = json.load(f)\nwith open(base_path + 'merchant_data.json', 'r') as f:\n    merchant_data = json.load(f)\n\n# 2. Filter for Target Merchant and Year\ntarget_merchant = 'Belles_cookbook_store'\ntarget_year = 2023\n\ndf_tx = df_payments[\n    (df_payments['merchant'] == target_merchant) & \n    (df_payments['year'] == target_year)\n].copy()\n\n# 3. Get Merchant Attributes\nmerchant_info = next((m for m in merchant_data if m['merchant'] == target_merchant), None)\nif not merchant_info:\n    raise ValueError(f\"Merchant {target_merchant} not found in merchant_data.json\")\n\nm_account_type = merchant_info['account_type']\nm_mcc = merchant_info['merchant_category_code']\nm_capture_delay = merchant_info['capture_delay']\n\n# 4. Pre-calculate Monthly Stats\n# Map day_of_year to month (2023 is not a leap year)\n# Create a date column\ndf_tx['date'] = pd.to_datetime(df_tx['year'] * 1000 + df_tx['day_of_year'], format='%Y%j')\ndf_tx['month'] = df_tx['date'].dt.month\n\n# Calculate Monthly Volume and Fraud Rate (Volume based)\n# Manual: \"Fraud is defined as the ratio of fraudulent volume over total volume.\"\nmonthly_stats = {}\nfor month in range(1, 13):\n    month_txs = df_tx[df_tx['month'] == month]\n    if month_txs.empty:\n        monthly_stats[month] = {'vol': 0, 'fraud_rate': 0}\n        continue\n    \n    total_vol = month_txs['eur_amount'].sum()\n    fraud_vol = month_txs[month_txs['has_fraudulent_dispute']]['eur_amount'].sum()\n    \n    fraud_rate = fraud_vol / total_vol if total_vol > 0 else 0\n    monthly_stats[month] = {\n        'vol': total_vol,\n        'fraud_rate': fraud_rate\n    }\n\n# 5. Calculate Fees\ntotal_fees = 0.0\nmatched_count = 0\nunmatched_count = 0\n\nfor idx, row in df_tx.iterrows():\n    # Build Transaction Context\n    month = row['month']\n    stats = monthly_stats.get(month, {'vol': 0, 'fraud_rate': 0})\n    \n    tx_context = {\n        'card_scheme': row['card_scheme'],\n        'account_type': m_account_type,\n        'merchant_category_code': m_mcc,\n        'is_credit': row['is_credit'],\n        'aci': row['aci'],\n        'intracountry': row['issuing_country'] == row['acquirer_country'],\n        'capture_delay': m_capture_delay,\n        'monthly_volume': stats['vol'],\n        'monthly_fraud_level': stats['fraud_rate']\n    }\n    \n    # Find Matching Rule\n    # We iterate through fees_data and take the first match.\n    # Assuming fees.json is ordered by priority or specificity is handled by the order.\n    matched_rule = None\n    for rule in fees_data:\n        if match_fee_rule(tx_context, rule):\n            matched_rule = rule\n            break\n    \n    if matched_rule:\n        fee = calculate_fee(row['eur_amount'], matched_rule)\n        total_fees += fee\n        matched_count += 1\n    else:\n        # Fallback or error logging\n        unmatched_count += 1\n        # print(f\"No rule found for tx {row['psp_reference']}\")\n\n# 6. Output Result\n# Question asks for total fees in euros.\nprint(f\"{total_fees:.2f}\")",
    "execution_output": "4144.32\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.15000000000000002,
    "plan_snapshot": [
      "Load the `payments.csv` file into a dataframe and filter the data to include only transactions where the `merchant` column is 'Belles_cookbook_store' and the `year` column is 2023.",
      "Load `merchant_data.json` to retrieve the `merchant_category_code`, `account_type`, and `capture_delay` for 'Belles_cookbook_store', load `fees.json`, and then calculate the `intracountry` status, monthly transaction volumes, and monthly fraud rates for the filtered payments data to prepare for fee rule matching."
    ]
  }
]