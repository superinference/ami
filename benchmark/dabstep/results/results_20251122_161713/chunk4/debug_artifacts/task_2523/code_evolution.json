[
  {
    "round": 1,
    "plan_steps": 1,
    "code_length": 2034,
    "code": "# Helper functions for robust data processing\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        return float(v)\n    return float(value)\n\ndef safe_get(df, column, default=None):\n    \"\"\"Safely get column from DataFrame, return default if not exists.\"\"\"\n    if isinstance(df, dict):\n        return df.get(column, default)\n    elif hasattr(df, 'columns') and column in df.columns:\n        return df[column]\n    return default\n\ndef is_not_empty(array):\n    \"\"\"Check if array/list is not empty. Handles numpy arrays safely.\"\"\"\n    if array is None:\n        return False\n    if hasattr(array, 'size'):  # numpy array\n        return array.size > 0\n    try:\n        return len(array) > 0\n    except TypeError:\n        return False\n\ndef safe_index(array, idx, default=None):\n    \"\"\"Safely get array element at index, return default if out of bounds.\"\"\"\n    try:\n        if 0 <= idx < len(array):\n            return array[idx]\n        return default\n    except (IndexError, TypeError, AttributeError):\n        return default\n\n\nimport json\nimport pandas as pd\n\n# Define file path\nfees_path = '/output/chunk4/data/context/fees.json'\n\n# Load fees.json\nwith open(fees_path, 'r') as f:\n    fees_data = json.load(f)\n\n# Filter for the fee rule with ID 12\nfee_rule_12 = next((fee for fee in fees_data if fee['ID'] == 12), None)\n\n# Print the result\nprint(\"Fee Rule ID 12 Details:\")\nprint(json.dumps(fee_rule_12, indent=4))",
    "execution_output": "Fee Rule ID 12 Details:\n{\n    \"ID\": 12,\n    \"card_scheme\": \"SwiftCharge\",\n    \"account_type\": [],\n    \"capture_delay\": null,\n    \"monthly_fraud_level\": null,\n    \"monthly_volume\": null,\n    \"merchant_category_code\": [\n        5411,\n        5412,\n        5499,\n        5912,\n        5812,\n        5813,\n        5911,\n        5983\n    ],\n    \"is_credit\": null,\n    \"aci\": [\n        \"C\",\n        \"B\"\n    ],\n    \"fixed_amount\": 0.01,\n    \"rate\": 40,\n    \"intracountry\": null\n}\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.1,
    "plan_snapshot": [
      "Load the `fees.json` file and filter the data to retrieve the specific fee rule details where the `ID` is equal to 12."
    ]
  },
  {
    "round": 2,
    "plan_steps": 2,
    "code_length": 7645,
    "code": "import json\nimport pandas as pd\nimport numpy as np\n\n# --- Helper Functions ---\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, k, m, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators for conversion\n        \n        # Handle Percentages\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n            \n        # Handle k/m suffixes (thousands/millions)\n        lower_v = v.lower()\n        if 'k' in lower_v:\n            return float(lower_v.replace('k', '')) * 1000\n        if 'm' in lower_v:\n            return float(lower_v.replace('m', '')) * 1000000\n            \n        # Handle Ranges (return mean) - fallback if used directly\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n                \n        try:\n            return float(v)\n        except ValueError:\n            return 0.0\n    return float(value)\n\ndef parse_range(range_str):\n    \"\"\"Parses a range string like '100k-1m', '>5', or '<3' into (min, max).\"\"\"\n    if not range_str:\n        return -float('inf'), float('inf')\n    \n    s = str(range_str).lower().strip()\n    \n    # Handle > (Greater than)\n    if s.startswith('>'):\n        val = coerce_to_float(s[1:])\n        return val, float('inf') # Treat > as strictly greater in check_condition\n        \n    # Handle < (Less than)\n    if s.startswith('<'):\n        val = coerce_to_float(s[1:])\n        return -float('inf'), val\n        \n    # Handle Range (e.g., 100k-1m)\n    if '-' in s:\n        parts = s.split('-')\n        min_val = coerce_to_float(parts[0])\n        max_val = coerce_to_float(parts[1])\n        return min_val, max_val\n    \n    # Exact match (treated as min=max)\n    val = coerce_to_float(s)\n    return val, val\n\ndef check_condition(value, condition_str):\n    \"\"\"Checks if a numeric value meets a condition string.\"\"\"\n    if condition_str is None:\n        return True\n        \n    min_v, max_v = parse_range(condition_str)\n    \n    # Handle strict inequalities based on string presence\n    s = str(condition_str).strip()\n    if s.startswith('>'):\n        return value > min_v\n    if s.startswith('<'):\n        return value < max_v\n        \n    # Default to inclusive range\n    return min_v <= value <= max_v\n\n# --- Main Analysis ---\n\ndef main():\n    # 1. Load Data\n    fees_path = '/output/chunk4/data/context/fees.json'\n    payments_path = '/output/chunk4/data/context/payments.csv'\n    merchant_path = '/output/chunk4/data/context/merchant_data.json'\n\n    with open(fees_path, 'r') as f:\n        fees_data = json.load(f)\n\n    merchant_data = pd.read_json(merchant_path)\n    payments = pd.read_csv(payments_path)\n\n    # 2. Get Fee Rule 12\n    fee_rule = next((f for f in fees_data if f['ID'] == 12), None)\n    if not fee_rule:\n        print(\"Fee ID 12 not found\")\n        return\n\n    # 3. Filter Payments for 2023\n    # We start with all 2023 transactions to ensure we can calculate monthly stats correctly later\n    df_2023 = payments[payments['year'] == 2023].copy()\n\n    # 4. Merge Merchant Data\n    # Add static merchant attributes (MCC, Account Type, Capture Delay) to transactions\n    df_merged = df_2023.merge(\n        merchant_data[['merchant', 'merchant_category_code', 'account_type', 'capture_delay']], \n        on='merchant', \n        how='left'\n    )\n\n    # 5. Apply Static Filters from Fee Rule\n    # We filter the dataframe down to potential matches\n\n    # Filter: Card Scheme\n    if fee_rule.get('card_scheme'):\n        df_merged = df_merged[df_merged['card_scheme'] == fee_rule['card_scheme']]\n\n    # Filter: Is Credit\n    if fee_rule.get('is_credit') is not None:\n        df_merged = df_merged[df_merged['is_credit'] == fee_rule['is_credit']]\n\n    # Filter: ACI (List)\n    if fee_rule.get('aci'):\n        # fee_rule['aci'] is a list, e.g., ['C', 'B']\n        df_merged = df_merged[df_merged['aci'].isin(fee_rule['aci'])]\n\n    # Filter: Merchant Category Code (List)\n    if fee_rule.get('merchant_category_code'):\n        df_merged = df_merged[df_merged['merchant_category_code'].isin(fee_rule['merchant_category_code'])]\n\n    # Filter: Account Type (List)\n    if fee_rule.get('account_type'):\n        df_merged = df_merged[df_merged['account_type'].isin(fee_rule['account_type'])]\n\n    # Filter: Intracountry\n    if fee_rule.get('intracountry') is not None:\n        is_intra = df_merged['issuing_country'] == df_merged['acquirer_country']\n        if fee_rule['intracountry']:\n            df_merged = df_merged[is_intra]\n        else:\n            df_merged = df_merged[~is_intra]\n\n    # Filter: Capture Delay\n    if fee_rule.get('capture_delay'):\n        # Exact match for categorical strings\n        df_merged = df_merged[df_merged['capture_delay'] == fee_rule['capture_delay']]\n\n    # 6. Dynamic Filters (Volume/Fraud)\n    # These require calculating stats on the TOTAL volume for the merchant/month, \n    # not just the filtered transactions.\n    \n    has_vol_rule = fee_rule.get('monthly_volume') is not None\n    has_fraud_rule = fee_rule.get('monthly_fraud_level') is not None\n\n    if has_vol_rule or has_fraud_rule:\n        # Identify candidate merchants and months from the currently filtered transactions\n        # We only care about months where a potentially matching transaction occurred\n        df_merged['month'] = pd.to_datetime(df_merged['day_of_year'], unit='D', origin='2022-12-31').dt.month\n        candidates = df_merged[['merchant', 'month']].drop_duplicates()\n        \n        # Calculate stats using the FULL 2023 dataset for these merchant/months\n        # (Volume/Fraud is based on ALL traffic, not just the specific card scheme/type)\n        full_2023 = payments[payments['year'] == 2023].copy()\n        full_2023['month'] = pd.to_datetime(full_2023['day_of_year'], unit='D', origin='2022-12-31').dt.month\n        \n        # Filter full data to only relevant merchants to speed up grouping\n        relevant_merchants = candidates['merchant'].unique()\n        full_2023 = full_2023[full_2023['merchant'].isin(relevant_merchants)]\n        \n        # Aggregate\n        stats = full_2023.groupby(['merchant', 'month']).agg(\n            monthly_vol=('eur_amount', 'sum'),\n            fraud_vol=('eur_amount', lambda x: x[full_2023.loc[x.index, 'has_fraudulent_dispute']].sum())\n        ).reset_index()\n        \n        stats['monthly_fraud_rate'] = stats['fraud_vol'] / stats['monthly_vol']\n        \n        # Identify valid (merchant, month) pairs that meet the rule\n        valid_pairs = set()\n        for _, row in stats.iterrows():\n            vol_ok = True\n            fraud_ok = True\n            \n            if has_vol_rule:\n                vol_ok = check_condition(row['monthly_vol'], fee_rule['monthly_volume'])\n                \n            if has_fraud_rule:\n                fraud_ok = check_condition(row['monthly_fraud_rate'], fee_rule['monthly_fraud_level'])\n                \n            if vol_ok and fraud_ok:\n                valid_pairs.add((row['merchant'], row['month']))\n        \n        # Filter our potential matches to only include those in valid months\n        df_merged = df_merged[df_merged.apply(lambda x: (x['merchant'], x['month']) in valid_pairs, axis=1)]\n\n    # 7. Output Result\n    affected_merchants = sorted(df_merged['merchant'].unique())\n    print(\", \".join(affected_merchants))\n\nif __name__ == \"__main__\":\n    main()",
    "execution_output": "Martinis_Fine_Steakhouse\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.15000000000000002,
    "plan_snapshot": [
      "Load the `fees.json` file and filter the data to retrieve the specific fee rule details where the `ID` is equal to 12.",
      "Load `merchant_data.json` to identify merchants with `merchant_category_code` in `[5411, 5412, 5499, 5912, 5812, 5813, 5911, 5983]`, then load `payments.csv` to filter transactions from 2023 where `card_scheme` is 'SwiftCharge' and `aci` is in `['C', 'B']`, and finally identify which of the MCC-filtered merchants appear in these filtered transactions."
    ]
  },
  {
    "round": 3,
    "plan_steps": 3,
    "code_length": 8516,
    "code": "import json\nimport pandas as pd\nimport numpy as np\n\n# --- Helper Functions ---\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, k, m, commas to float. Handles common formats.\"\"\"\n    if value is None:\n        return 0.0\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators for conversion\n        \n        # Handle Percentages\n        if '%' in v:\n            try:\n                return float(v.replace('%', '')) / 100\n            except ValueError:\n                return 0.0\n            \n        # Handle k/m suffixes (thousands/millions)\n        lower_v = v.lower()\n        if 'k' in lower_v:\n            try:\n                return float(lower_v.replace('k', '')) * 1000\n            except ValueError:\n                pass\n        if 'm' in lower_v:\n            try:\n                return float(lower_v.replace('m', '')) * 1000000\n            except ValueError:\n                pass\n            \n        # Handle Ranges (return mean) - fallback if used directly\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n                \n        try:\n            return float(v)\n        except ValueError:\n            return 0.0\n    return float(value)\n\ndef parse_range(range_str):\n    \"\"\"Parses a range string like '100k-1m', '>5', or '<3' into (min, max).\"\"\"\n    if not range_str:\n        return -float('inf'), float('inf')\n    \n    s = str(range_str).lower().strip()\n    \n    # Handle > (Greater than)\n    if s.startswith('>'):\n        val = coerce_to_float(s[1:])\n        return val, float('inf') # Treat > as strictly greater in check_condition\n        \n    # Handle < (Less than)\n    if s.startswith('<'):\n        val = coerce_to_float(s[1:])\n        return -float('inf'), val\n        \n    # Handle Range (e.g., 100k-1m)\n    if '-' in s:\n        parts = s.split('-')\n        min_val = coerce_to_float(parts[0])\n        max_val = coerce_to_float(parts[1])\n        return min_val, max_val\n    \n    # Exact match (treated as min=max)\n    val = coerce_to_float(s)\n    return val, val\n\ndef check_condition(value, condition_str):\n    \"\"\"Checks if a numeric value meets a condition string.\"\"\"\n    if condition_str is None:\n        return True\n        \n    min_v, max_v = parse_range(condition_str)\n    \n    # Handle strict inequalities based on string presence\n    s = str(condition_str).strip()\n    if s.startswith('>'):\n        return value > min_v\n    if s.startswith('<'):\n        return value < max_v\n        \n    # Default to inclusive range\n    return min_v <= value <= max_v\n\n# --- Main Analysis ---\n\ndef main():\n    # 1. Load Data\n    fees_path = '/output/chunk4/data/context/fees.json'\n    payments_path = '/output/chunk4/data/context/payments.csv'\n    merchant_path = '/output/chunk4/data/context/merchant_data.json'\n\n    try:\n        with open(fees_path, 'r') as f:\n            fees_data = json.load(f)\n        \n        merchant_data = pd.read_json(merchant_path)\n        payments = pd.read_csv(payments_path)\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        return\n\n    # 2. Get Fee Rule 12\n    fee_rule = next((f for f in fees_data if f['ID'] == 12), None)\n    if not fee_rule:\n        print(\"Fee ID 12 not found\")\n        return\n\n    # Debug: Print rule details to ensure we understand criteria\n    # print(f\"DEBUG: Analyzing Fee Rule 12: {fee_rule}\")\n\n    # 3. Filter Payments for 2023\n    df_2023 = payments[payments['year'] == 2023].copy()\n\n    # 4. Merge Merchant Data\n    # Add static merchant attributes (MCC, Account Type, Capture Delay) to transactions\n    # Ensure column names match: merchant_data has 'merchant', 'merchant_category_code', 'account_type', 'capture_delay'\n    df_merged = df_2023.merge(\n        merchant_data[['merchant', 'merchant_category_code', 'account_type', 'capture_delay']], \n        on='merchant', \n        how='left'\n    )\n\n    # 5. Apply Static Filters from Fee Rule\n    \n    # Filter: Card Scheme\n    if fee_rule.get('card_scheme'):\n        df_merged = df_merged[df_merged['card_scheme'] == fee_rule['card_scheme']]\n\n    # Filter: Is Credit (Boolean or Null)\n    if fee_rule.get('is_credit') is not None:\n        df_merged = df_merged[df_merged['is_credit'] == fee_rule['is_credit']]\n\n    # Filter: ACI (List of strings)\n    # If fee_rule['aci'] is empty list or None, it applies to all.\n    if fee_rule.get('aci'): \n        df_merged = df_merged[df_merged['aci'].isin(fee_rule['aci'])]\n\n    # Filter: Merchant Category Code (List of ints)\n    if fee_rule.get('merchant_category_code'):\n        df_merged = df_merged[df_merged['merchant_category_code'].isin(fee_rule['merchant_category_code'])]\n\n    # Filter: Account Type (List of strings)\n    if fee_rule.get('account_type'):\n        df_merged = df_merged[df_merged['account_type'].isin(fee_rule['account_type'])]\n\n    # Filter: Intracountry (Boolean or Null)\n    if fee_rule.get('intracountry') is not None:\n        # Intracountry means issuing_country == acquirer_country\n        is_intra = df_merged['issuing_country'] == df_merged['acquirer_country']\n        if fee_rule['intracountry']:\n            df_merged = df_merged[is_intra]\n        else:\n            df_merged = df_merged[~is_intra]\n\n    # Filter: Capture Delay (String)\n    if fee_rule.get('capture_delay'):\n        # Exact match for categorical strings\n        df_merged = df_merged[df_merged['capture_delay'] == fee_rule['capture_delay']]\n\n    # 6. Dynamic Filters (Volume/Fraud)\n    # These require calculating stats on the TOTAL volume for the merchant/month.\n    \n    has_vol_rule = fee_rule.get('monthly_volume') is not None\n    has_fraud_rule = fee_rule.get('monthly_fraud_level') is not None\n\n    if has_vol_rule or has_fraud_rule:\n        # We need to check if the merchant met the volume/fraud criteria in the specific month \n        # where the transaction occurred.\n        \n        # Add month column to filtered transactions\n        df_merged['month'] = pd.to_datetime(df_merged['day_of_year'], unit='D', origin='2022-12-31').dt.month\n        \n        # Get unique (merchant, month) pairs that are candidates\n        candidates = df_merged[['merchant', 'month']].drop_duplicates()\n        \n        if candidates.empty:\n            print(\"\") # No candidates left\n            return\n\n        # Calculate stats using the FULL 2023 dataset for these merchant/months\n        full_2023 = payments[payments['year'] == 2023].copy()\n        full_2023['month'] = pd.to_datetime(full_2023['day_of_year'], unit='D', origin='2022-12-31').dt.month\n        \n        # Filter full data to only relevant merchants to speed up grouping\n        relevant_merchants = candidates['merchant'].unique()\n        full_2023 = full_2023[full_2023['merchant'].isin(relevant_merchants)]\n        \n        # Aggregate monthly stats\n        stats = full_2023.groupby(['merchant', 'month']).agg(\n            monthly_vol=('eur_amount', 'sum'),\n            fraud_vol=('eur_amount', lambda x: x[full_2023.loc[x.index, 'has_fraudulent_dispute']].sum())\n        ).reset_index()\n        \n        stats['monthly_fraud_rate'] = stats['fraud_vol'] / stats['monthly_vol']\n        \n        # Identify valid (merchant, month) pairs that meet the rule\n        valid_pairs = set()\n        for _, row in stats.iterrows():\n            vol_ok = True\n            fraud_ok = True\n            \n            if has_vol_rule:\n                vol_ok = check_condition(row['monthly_vol'], fee_rule['monthly_volume'])\n                \n            if has_fraud_rule:\n                fraud_ok = check_condition(row['monthly_fraud_rate'], fee_rule['monthly_fraud_level'])\n                \n            if vol_ok and fraud_ok:\n                valid_pairs.add((row['merchant'], row['month']))\n        \n        # Filter our potential matches to only include those in valid months\n        # Create a tuple column for fast filtering\n        df_merged['merchant_month'] = list(zip(df_merged['merchant'], df_merged['month']))\n        df_merged = df_merged[df_merged['merchant_month'].isin(valid_pairs)]\n\n    # 7. Output Result\n    affected_merchants = sorted(df_merged['merchant'].unique())\n    \n    # Format output as requested (comma separated list)\n    print(\", \".join(affected_merchants))\n\nif __name__ == \"__main__\":\n    main()",
    "execution_output": "Martinis_Fine_Steakhouse\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "sufficient",
    "temperature": 0.2,
    "plan_snapshot": [
      "Load the `fees.json` file and filter the data to retrieve the specific fee rule details where the `ID` is equal to 12.",
      "Load `merchant_data.json` to identify merchants with `merchant_category_code` in `[5411, 5412, 5499, 5912, 5812, 5813, 5911, 5983]`, then load `payments.csv` to filter transactions from 2023 where `card_scheme` is 'SwiftCharge' and `aci` is in `['C', 'B']`, and finally identify which of the MCC-filtered merchants appear in these filtered transactions.",
      "Load `fees.json` to retrieve the full criteria for Fee ID 12 (specifically checking `is_credit`, `intracountry`, and `capture_delay` requirements), then load `payments.csv` and `merchant_data.json` to filter 2023 transactions that match *all* Fee 12 criteria, and report the unique merchants."
    ]
  }
]