[
  {
    "round": 1,
    "plan_steps": 1,
    "code_length": 3089,
    "code": "# Helper functions for robust data processing\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        return float(v)\n    return float(value)\n\ndef safe_get(df, column, default=None):\n    \"\"\"Safely get column from DataFrame, return default if not exists.\"\"\"\n    if isinstance(df, dict):\n        return df.get(column, default)\n    elif hasattr(df, 'columns') and column in df.columns:\n        return df[column]\n    return default\n\ndef is_not_empty(array):\n    \"\"\"Check if array/list is not empty. Handles numpy arrays safely.\"\"\"\n    if array is None:\n        return False\n    if hasattr(array, 'size'):  # numpy array\n        return array.size > 0\n    try:\n        return len(array) > 0\n    except TypeError:\n        return False\n\ndef safe_index(array, idx, default=None):\n    \"\"\"Safely get array element at index, return default if out of bounds.\"\"\"\n    try:\n        if 0 <= idx < len(array):\n            return array[idx]\n        return default\n    except (IndexError, TypeError, AttributeError):\n        return default\n\n\nimport pandas as pd\nimport json\n\n# Define file path\nmerchant_data_path = '/output/chunk2/data/context/merchant_data.json'\n\n# Load merchant data\ntry:\n    with open(merchant_data_path, 'r') as f:\n        merchant_data = json.load(f)\n    \n    # Convert to DataFrame for easier handling\n    df_merchant = pd.DataFrame(merchant_data)\n    \n    # Filter for the specific merchant \"Rafa_AI\"\n    merchant_name = \"Rafa_AI\"\n    rafa_attributes = df_merchant[df_merchant['merchant'] == merchant_name]\n    \n    if not rafa_attributes.empty:\n        # Extract the first (and likely only) row as a dictionary\n        attributes_dict = rafa_attributes.iloc[0].to_dict()\n        \n        # Extract specific fields requested in the plan\n        mcc = attributes_dict.get('merchant_category_code')\n        account_type = attributes_dict.get('account_type')\n        capture_delay = attributes_dict.get('capture_delay')\n        acquirers = attributes_dict.get('acquirer')\n        \n        print(f\"Successfully retrieved attributes for {merchant_name}:\")\n        print(f\"Merchant Category Code: {mcc}\")\n        print(f\"Account Type: {account_type}\")\n        print(f\"Capture Delay: {capture_delay}\")\n        print(f\"Acquirers: {acquirers}\")\n        print(\"-\" * 30)\n        print(\"Full Attribute Dictionary:\", attributes_dict)\n    else:\n        print(f\"Merchant '{merchant_name}' not found in the data.\")\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
    "execution_output": "Successfully retrieved attributes for Rafa_AI:\nMerchant Category Code: 7372\nAccount Type: D\nCapture Delay: 7\nAcquirers: ['tellsons_bank']\n------------------------------\nFull Attribute Dictionary: {'merchant': 'Rafa_AI', 'capture_delay': '7', 'acquirer': ['tellsons_bank'], 'merchant_category_code': 7372, 'account_type': 'D'}\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.1,
    "plan_snapshot": [
      "Load the `merchant_data.json` file and filter for the merchant \"Rafa_AI\" to retrieve its static attributes such as `merchant_category_code`, `account_type`, and `capture_delay`."
    ]
  },
  {
    "round": 2,
    "plan_steps": 2,
    "code_length": 8373,
    "code": "import pandas as pd\nimport json\nimport numpy as np\n\n# ---------------------------------------------------------\n# HELPER FUNCTIONS\n# ---------------------------------------------------------\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        try:\n            return float(v)\n        except ValueError:\n            return 0.0\n    return 0.0\n\ndef parse_range(range_str):\n    \"\"\"Parses a range string like '100k-1m' or '<3' into (min, max).\"\"\"\n    if not isinstance(range_str, str):\n        return None, None\n    \n    s = range_str.lower().replace(',', '').replace('%', '')\n    multiplier = 1\n    if 'k' in s:\n        multiplier = 1000\n        s = s.replace('k', '')\n    elif 'm' in s:\n        multiplier = 1000000\n        s = s.replace('m', '')\n        \n    if '-' in s:\n        try:\n            parts = s.split('-')\n            return float(parts[0]) * multiplier, float(parts[1]) * multiplier\n        except:\n            return None, None\n    elif '>' in s:\n        try:\n            val = float(s.replace('>', '')) * multiplier\n            return val, float('inf')\n        except:\n            return None, None\n    elif '<' in s:\n        try:\n            val = float(s.replace('<', '')) * multiplier\n            return float('-inf'), val\n        except:\n            return None, None\n    else:\n        try:\n            val = float(s) * multiplier\n            return val, val\n        except:\n            return None, None\n\ndef check_range_match(value, rule_range_str, is_percentage=False):\n    \"\"\"Checks if a value fits within a rule's range string.\"\"\"\n    if rule_range_str is None:\n        return True\n    \n    # Special handling for percentage strings in rules\n    if is_percentage and isinstance(rule_range_str, str) and '%' in rule_range_str:\n        clean_range = rule_range_str.replace('%', '')\n        min_v, max_v = parse_range(clean_range)\n        if min_v is not None:\n            # parse_range returns raw numbers (e.g. 7, 8 for 7-8), divide by 100 for percentage comparison\n            return (min_v/100) <= value <= (max_v/100)\n            \n    # Standard handling\n    min_v, max_v = parse_range(rule_range_str)\n    if min_v is None:\n        return False \n    return min_v <= value <= max_v\n\ndef match_fee_rule(tx_ctx, rule):\n    \"\"\"\n    Determines if a fee rule applies to a transaction context.\n    tx_ctx: dict containing transaction/merchant details\n    rule: dict from fees.json\n    \"\"\"\n    # 1. Card Scheme (Exact match)\n    if rule.get('card_scheme') and rule['card_scheme'] != tx_ctx.get('card_scheme'):\n        return False\n\n    # 2. Account Type (List match)\n    if rule.get('account_type'):\n        if tx_ctx.get('account_type') not in rule['account_type']:\n            return False\n\n    # 3. Merchant Category Code (List match)\n    if rule.get('merchant_category_code'):\n        if tx_ctx.get('mcc') not in rule['merchant_category_code']:\n            return False\n\n    # 4. Capture Delay (Exact match or Range)\n    if rule.get('capture_delay'):\n        rule_cd = rule['capture_delay']\n        tx_cd = tx_ctx.get('capture_delay')\n        \n        if rule_cd == tx_cd:\n            pass\n        elif tx_cd and tx_cd.isdigit():\n            days = int(tx_cd)\n            if rule_cd == '<3' and days < 3: pass\n            elif rule_cd == '>5' and days > 5: pass\n            elif rule_cd == '3-5' and 3 <= days <= 5: pass\n            else: return False\n        else:\n            return False\n\n    # 5. Is Credit (Boolean match)\n    if rule.get('is_credit') is not None:\n        if rule['is_credit'] != tx_ctx.get('is_credit'):\n            return False\n\n    # 6. ACI (List match)\n    if rule.get('aci'):\n        if tx_ctx.get('aci') not in rule['aci']:\n            return False\n\n    # 7. Intracountry (Boolean match)\n    if rule.get('intracountry') is not None:\n        # Assuming 1.0/0.0 in JSON maps to True/False\n        rule_intra = bool(float(rule['intracountry']))\n        if rule_intra != tx_ctx.get('intracountry'):\n            return False\n\n    # 8. Monthly Volume (Range match)\n    if rule.get('monthly_volume'):\n        if not check_range_match(tx_ctx.get('monthly_volume', 0), rule['monthly_volume']):\n            return False\n\n    # 9. Monthly Fraud Level (Range match)\n    if rule.get('monthly_fraud_level'):\n        if not check_range_match(tx_ctx.get('monthly_fraud_level', 0), rule['monthly_fraud_level'], is_percentage=True):\n            return False\n\n    return True\n\n# ---------------------------------------------------------\n# MAIN SCRIPT\n# ---------------------------------------------------------\n\n# Load Data\npayments_path = '/output/chunk2/data/context/payments.csv'\nfees_path = '/output/chunk2/data/context/fees.json'\nmerchant_path = '/output/chunk2/data/context/merchant_data.json'\n\ntry:\n    df_payments = pd.read_csv(payments_path)\n    with open(fees_path, 'r') as f:\n        fees_data = json.load(f)\n    with open(merchant_path, 'r') as f:\n        merchant_data = json.load(f)\n\n    # 1. Filter for Rafa_AI\n    merchant_name = 'Rafa_AI'\n    df_rafa = df_payments[df_payments['merchant'] == merchant_name].copy()\n\n    if df_rafa.empty:\n        print(\"No transactions found for Rafa_AI\")\n    else:\n        # 2. Get Static Merchant Attributes\n        merchant_info = next((item for item in merchant_data if item[\"merchant\"] == merchant_name), None)\n        if not merchant_info:\n            print(f\"Merchant {merchant_name} not found in merchant_data.json\")\n            exit()\n\n        static_ctx = {\n            'account_type': merchant_info.get('account_type'),\n            'mcc': merchant_info.get('merchant_category_code'),\n            'capture_delay': merchant_info.get('capture_delay')\n        }\n\n        # 3. Calculate Monthly Stats (Volume and Fraud)\n        # Convert day_of_year to month (2023)\n        df_rafa['date'] = pd.to_datetime(df_rafa['year'] * 1000 + df_rafa['day_of_year'], format='%Y%j')\n        df_rafa['month'] = df_rafa['date'].dt.month\n\n        # Group by month to calculate stats\n        monthly_stats = df_rafa.groupby('month').agg(\n            total_vol=('eur_amount', 'sum'),\n            fraud_vol=('eur_amount', lambda x: x[df_rafa.loc[x.index, 'has_fraudulent_dispute']].sum())\n        ).reset_index()\n\n        monthly_stats['fraud_rate'] = monthly_stats['fraud_vol'] / monthly_stats['total_vol']\n        \n        # Create a lookup for monthly stats: month -> {vol, fraud_rate}\n        stats_lookup = monthly_stats.set_index('month').to_dict('index')\n\n        # 4. Identify Unique Transaction Profiles\n        # Group by attributes that affect fees to optimize matching\n        profile_cols = ['card_scheme', 'is_credit', 'aci', 'issuing_country', 'acquirer_country', 'month']\n        unique_profiles = df_rafa[profile_cols].drop_duplicates()\n\n        applicable_fee_ids = set()\n\n        # 5. Match Rules\n        for _, row in unique_profiles.iterrows():\n            month = row['month']\n            stats = stats_lookup.get(month, {'total_vol': 0, 'fraud_rate': 0})\n            \n            # Build Context\n            ctx = {\n                'card_scheme': row['card_scheme'],\n                'is_credit': row['is_credit'],\n                'aci': row['aci'],\n                'intracountry': row['issuing_country'] == row['acquirer_country'],\n                'monthly_volume': stats['total_vol'],\n                'monthly_fraud_level': stats['fraud_rate'],\n                **static_ctx # Add static attributes\n            }\n            \n            # Check all rules\n            for rule in fees_data:\n                if match_fee_rule(ctx, rule):\n                    applicable_fee_ids.add(rule['ID'])\n\n        # 6. Output\n        sorted_ids = sorted(list(applicable_fee_ids))\n        print(f\"Applicable Fee IDs for {merchant_name} in 2023:\")\n        print(\", \".join(map(str, sorted_ids)))\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
    "execution_output": "Applicable Fee IDs for Rafa_AI in 2023:\n17, 36, 51, 65, 107, 123, 150, 163, 183, 276, 286, 304, 359, 384, 398, 427, 428, 471, 477, 498, 595, 626, 631, 634, 701, 709, 722, 741, 787, 813, 861, 888, 892\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.15000000000000002,
    "plan_snapshot": [
      "Load the `merchant_data.json` file and filter for the merchant \"Rafa_AI\" to retrieve its static attributes such as `merchant_category_code`, `account_type`, and `capture_delay`.",
      "Load the `payments.csv` file, filter for the merchant \"Rafa_AI\", and calculate the total monthly transaction volume, the monthly fraud rate (fraudulent volume / total volume), and extract unique combinations of `card_scheme`, `is_credit`, `aci`, and `intracountry` (derived by comparing `issuing_country` and `acquirer_country`) to prepare for matching against fee rules."
    ]
  }
]