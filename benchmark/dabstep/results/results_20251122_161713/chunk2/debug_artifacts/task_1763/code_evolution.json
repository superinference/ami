[
  {
    "round": 1,
    "plan_steps": 1,
    "code_length": 2668,
    "code": "# Helper functions for robust data processing\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        return float(v)\n    return float(value)\n\ndef safe_get(df, column, default=None):\n    \"\"\"Safely get column from DataFrame, return default if not exists.\"\"\"\n    if isinstance(df, dict):\n        return df.get(column, default)\n    elif hasattr(df, 'columns') and column in df.columns:\n        return df[column]\n    return default\n\ndef is_not_empty(array):\n    \"\"\"Check if array/list is not empty. Handles numpy arrays safely.\"\"\"\n    if array is None:\n        return False\n    if hasattr(array, 'size'):  # numpy array\n        return array.size > 0\n    try:\n        return len(array) > 0\n    except TypeError:\n        return False\n\ndef safe_index(array, idx, default=None):\n    \"\"\"Safely get array element at index, return default if out of bounds.\"\"\"\n    try:\n        if 0 <= idx < len(array):\n            return array[idx]\n        return default\n    except (IndexError, TypeError, AttributeError):\n        return default\n\n\nimport pandas as pd\n\n# Load the payments data\npayments_path = '/output/chunk2/data/context/payments.csv'\ndf_payments = pd.read_csv(payments_path)\n\n# Filter for merchant 'Crossfit_Hanna' and January 2023 (day_of_year 1-31)\n# The 'year' column is confirmed to be 2023 for the whole dataset, so we filter by day_of_year\nfiltered_df = df_payments[\n    (df_payments['merchant'] == 'Crossfit_Hanna') & \n    (df_payments['day_of_year'] >= 1) & \n    (df_payments['day_of_year'] <= 31)\n]\n\n# Output results\nprint(f\"Original dataset size: {len(df_payments)}\")\nprint(f\"Filtered dataset size (Crossfit_Hanna, Jan 2023): {len(filtered_df)}\")\n\n# Calculate verification metrics to match Ground Truth\ntotal_volume = filtered_df['eur_amount'].sum()\nfraud_volume = filtered_df[filtered_df['has_fraudulent_dispute'] == True]['eur_amount'].sum()\n\nprint(f\"Total Volume: {total_volume:.2f}\")\nprint(f\"Fraud Volume: {fraud_volume:.2f}\")\n\n# Display a sample to confirm structure\nprint(\"\\nFirst 5 rows of filtered data:\")\nprint(filtered_df.head())",
    "execution_output": "Original dataset size: 138236\nFiltered dataset size (Crossfit_Hanna, Jan 2023): 4846\nTotal Volume: 431222.93\nFraud Volume: 42617.60\n\nFirst 5 rows of filtered data:\n    psp_reference        merchant  ... aci  acquirer_country\n0     20034594130  Crossfit_Hanna  ...   F                NL\n8     21324863343  Crossfit_Hanna  ...   F                NL\n33    33987304310  Crossfit_Hanna  ...   F                NL\n67    65649845274  Crossfit_Hanna  ...   D                GB\n89    15786948544  Crossfit_Hanna  ...   D                NL\n\n[5 rows x 21 columns]\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.1,
    "plan_snapshot": [
      "Load the `payments.csv` file and filter the data to include only transactions for the merchant 'Crossfit_Hanna' that occurred in January 2023 (where `day_of_year` is between 1 and 31)."
    ]
  },
  {
    "round": 2,
    "plan_steps": 2,
    "code_length": 8367,
    "code": "import pandas as pd\nimport json\nimport numpy as np\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# HELPER FUNCTIONS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas, k, m suffixes to float.\"\"\"\n    if value is None:\n        return 0.0\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().lower().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.replace('>', '').replace('<', '').replace('=', '') # Remove operators for raw value parsing\n        \n        # Handle percentages\n        if '%' in v:\n            return float(v.replace('%', '')) / 100.0\n            \n        # Handle k/m suffixes\n        multiplier = 1.0\n        if v.endswith('k'):\n            multiplier = 1_000.0\n            v = v[:-1]\n        elif v.endswith('m'):\n            multiplier = 1_000_000.0\n            v = v[:-1]\n            \n        try:\n            return float(v) * multiplier\n        except ValueError:\n            return 0.0\n    return 0.0\n\ndef parse_range_check(rule_value, actual_value):\n    \"\"\"\n    Check if actual_value falls within the rule_value range.\n    rule_value examples: '100k-1m', '>5', '<3', '7.7%-8.3%', 'immediate', 'manual'\n    \"\"\"\n    if rule_value is None:\n        return True\n        \n    # Handle string equality for non-numeric rules (e.g., 'immediate', 'manual')\n    if isinstance(rule_value, str) and not any(c.isdigit() for c in rule_value):\n        return rule_value.lower() == str(actual_value).lower()\n\n    # Handle numeric comparisons\n    try:\n        # Convert actual_value to float if it's a string number (e.g. \"1\")\n        if isinstance(actual_value, str):\n            if actual_value.lower() in ['immediate', 'manual']:\n                return rule_value.lower() == actual_value.lower()\n            actual_float = float(actual_value)\n        else:\n            actual_float = float(actual_value)\n            \n        rv = str(rule_value).lower().strip()\n        \n        # Range \"X-Y\"\n        if '-' in rv:\n            parts = rv.split('-')\n            min_val = coerce_to_float(parts[0])\n            max_val = coerce_to_float(parts[1])\n            return min_val <= actual_float <= max_val\n            \n        # Greater than\n        if rv.startswith('>'):\n            limit = coerce_to_float(rv[1:])\n            return actual_float > limit\n            \n        # Less than\n        if rv.startswith('<'):\n            limit = coerce_to_float(rv[1:])\n            return actual_float < limit\n            \n        # Exact match (numeric)\n        return actual_float == coerce_to_float(rv)\n        \n    except Exception:\n        # Fallback for complex strings or mismatches\n        return str(rule_value) == str(actual_value)\n\ndef match_fee_rule(transaction, rule):\n    \"\"\"\n    Check if a fee rule applies to a specific transaction context.\n    transaction dict must contain:\n      - card_scheme, is_credit, aci, intracountry (from payment)\n      - account_type, merchant_category_code, capture_delay (from merchant data)\n      - monthly_volume, monthly_fraud_level (calculated stats)\n    \"\"\"\n    # 1. Card Scheme (Exact match)\n    if rule.get('card_scheme') and rule['card_scheme'] != transaction['card_scheme']:\n        return False\n\n    # 2. Account Type (List match - Wildcard allowed)\n    if rule.get('account_type'):\n        if transaction['account_type'] not in rule['account_type']:\n            return False\n\n    # 3. Merchant Category Code (List match - Wildcard allowed)\n    if rule.get('merchant_category_code'):\n        if transaction['merchant_category_code'] not in rule['merchant_category_code']:\n            return False\n\n    # 4. ACI (List match - Wildcard allowed)\n    if rule.get('aci'):\n        if transaction['aci'] not in rule['aci']:\n            return False\n\n    # 5. Is Credit (Boolean match - Wildcard allowed)\n    if rule.get('is_credit') is not None:\n        # Handle string 'None' or actual None in JSON\n        if str(rule['is_credit']).lower() != 'none': \n            if bool(rule['is_credit']) != transaction['is_credit']:\n                return False\n\n    # 6. Intracountry (Boolean match - Wildcard allowed)\n    if rule.get('intracountry') is not None:\n        # JSON might have 0.0/1.0 or boolean\n        rule_intra = rule['intracountry']\n        if str(rule_intra).lower() != 'none':\n            is_intra_rule = bool(float(rule_intra)) if isinstance(rule_intra, (int, float, str)) else rule_intra\n            if is_intra_rule != transaction['intracountry']:\n                return False\n\n    # 7. Capture Delay (Range/Value match - Wildcard allowed)\n    if rule.get('capture_delay'):\n        if not parse_range_check(rule['capture_delay'], transaction['capture_delay']):\n            return False\n\n    # 8. Monthly Volume (Range match - Wildcard allowed)\n    if rule.get('monthly_volume'):\n        if not parse_range_check(rule['monthly_volume'], transaction['monthly_volume']):\n            return False\n\n    # 9. Monthly Fraud Level (Range match - Wildcard allowed)\n    if rule.get('monthly_fraud_level'):\n        if not parse_range_check(rule['monthly_fraud_level'], transaction['monthly_fraud_level']):\n            return False\n\n    return True\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# MAIN SCRIPT\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# 1. Load Data\npayments_path = '/output/chunk2/data/context/payments.csv'\nfees_path = '/output/chunk2/data/context/fees.json'\nmerchant_data_path = '/output/chunk2/data/context/merchant_data.json'\n\ndf_payments = pd.read_csv(payments_path)\nwith open(fees_path, 'r') as f:\n    fees_data = json.load(f)\nwith open(merchant_data_path, 'r') as f:\n    merchant_data_list = json.load(f)\n\n# 2. Filter Transactions (Crossfit_Hanna, Jan 2023)\ntarget_merchant = 'Crossfit_Hanna'\nfiltered_df = df_payments[\n    (df_payments['merchant'] == target_merchant) & \n    (df_payments['day_of_year'] >= 1) & \n    (df_payments['day_of_year'] <= 31) &\n    (df_payments['year'] == 2023)\n].copy()\n\n# 3. Get Merchant Static Data\nmerchant_info = next((m for m in merchant_data_list if m['merchant'] == target_merchant), None)\nif not merchant_info:\n    print(f\"Error: Merchant {target_merchant} not found in merchant_data.json\")\n    exit()\n\n# 4. Calculate Monthly Stats\ntotal_volume = filtered_df['eur_amount'].sum()\nfraud_volume = filtered_df[filtered_df['has_fraudulent_dispute'] == True]['eur_amount'].sum()\nfraud_rate = fraud_volume / total_volume if total_volume > 0 else 0.0\n\nprint(f\"Merchant: {target_merchant}\")\nprint(f\"Total Volume (Jan): {total_volume:.2f}\")\nprint(f\"Fraud Volume (Jan): {fraud_volume:.2f}\")\nprint(f\"Fraud Rate: {fraud_rate:.4%}\")\nprint(f\"Static Info: MCC={merchant_info['merchant_category_code']}, Account={merchant_info['account_type']}, Delay={merchant_info['capture_delay']}\")\n\n# 5. Identify Applicable Fee IDs\napplicable_fee_ids = set()\n\n# Optimization: Iterate over unique transaction profiles instead of every row\n# Attributes that vary per transaction and affect fees:\n# card_scheme, is_credit, aci, issuing_country, acquirer_country\nunique_tx_profiles = filtered_df[[\n    'card_scheme', 'is_credit', 'aci', 'issuing_country', 'acquirer_country'\n]].drop_duplicates()\n\nprint(f\"Unique transaction profiles to check: {len(unique_tx_profiles)}\")\n\nfor _, row in unique_tx_profiles.iterrows():\n    # Construct transaction context for matching\n    tx_context = {\n        # Transaction specific\n        'card_scheme': row['card_scheme'],\n        'is_credit': row['is_credit'],\n        'aci': row['aci'],\n        'intracountry': row['issuing_country'] == row['acquirer_country'],\n        \n        # Merchant specific (static)\n        'account_type': merchant_info['account_type'],\n        'merchant_category_code': merchant_info['merchant_category_code'],\n        'capture_delay': merchant_info['capture_delay'],\n        \n        # Monthly stats (static for the month)\n        'monthly_volume': total_volume,\n        'monthly_fraud_level': fraud_rate\n    }\n    \n    # Check against all fee rules\n    for rule in fees_data:\n        if match_fee_rule(tx_context, rule):\n            applicable_fee_ids.add(rule['ID'])\n\n# 6. Output Results\nsorted_ids = sorted(list(applicable_fee_ids))\nprint(\"\\nApplicable Fee IDs:\")\nprint(\", \".join(map(str, sorted_ids)))",
    "execution_output": "Merchant: Crossfit_Hanna\nTotal Volume (Jan): 431222.93\nFraud Volume (Jan): 42617.60\nFraud Rate: 9.8830%\nStatic Info: MCC=7997, Account=F, Delay=manual\nUnique transaction profiles to check: 328\n\nApplicable Fee IDs:\n29, 36, 51, 64, 65, 89, 107, 123, 150, 163, 276, 304, 381, 384, 428, 454, 473, 477, 536, 572, 595, 626, 631, 678, 680, 704, 709, 741, 792, 813, 861, 871, 884\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.15000000000000002,
    "plan_snapshot": [
      "Load the `payments.csv` file and filter the data to include only transactions for the merchant 'Crossfit_Hanna' that occurred in January 2023 (where `day_of_year` is between 1 and 31).",
      "Load `merchant_data.json` to retrieve the static attributes (merchant_category_code, account_type, capture_delay) for 'Crossfit_Hanna', load `fees.json`, and then using the previously calculated total volume and fraud volume (to determine the monthly tiers) and the unique transaction attributes (card_scheme, is_credit, aci, and intracountry status derived from issuing_country and acquirer_country) from the filtered payments data, identify and list all Fee IDs from `fees.json` that match the transactions."
    ]
  }
]