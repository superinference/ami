[
  {
    "round": 1,
    "plan_steps": 1,
    "code_length": 2333,
    "code": "# Helper functions for robust data processing\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        return float(v)\n    return float(value)\n\ndef safe_get(df, column, default=None):\n    \"\"\"Safely get column from DataFrame, return default if not exists.\"\"\"\n    if isinstance(df, dict):\n        return df.get(column, default)\n    elif hasattr(df, 'columns') and column in df.columns:\n        return df[column]\n    return default\n\ndef is_not_empty(array):\n    \"\"\"Check if array/list is not empty. Handles numpy arrays safely.\"\"\"\n    if array is None:\n        return False\n    if hasattr(array, 'size'):  # numpy array\n        return array.size > 0\n    try:\n        return len(array) > 0\n    except TypeError:\n        return False\n\ndef safe_index(array, idx, default=None):\n    \"\"\"Safely get array element at index, return default if out of bounds.\"\"\"\n    try:\n        if 0 <= idx < len(array):\n            return array[idx]\n        return default\n    except (IndexError, TypeError, AttributeError):\n        return default\n\n\nimport pandas as pd\n\n# Define file path\npayments_path = '/output/chunk5/data/context/payments.csv'\n\n# Load the payments data\ndf_payments = pd.read_csv(payments_path)\n\n# Filter for the specific merchant and year\nmerchant_name = \"Martinis_Fine_Steakhouse\"\ntarget_year = 2023\n\n# Apply filters\nfiltered_df = df_payments[\n    (df_payments['merchant'] == merchant_name) & \n    (df_payments['year'] == target_year)\n]\n\n# Display the result to verify\nprint(f\"Loaded payments data. Total rows: {len(df_payments)}\")\nprint(f\"Filtered for merchant '{merchant_name}' and year {target_year}.\")\nprint(f\"Resulting rows: {len(filtered_df)}\")\nprint(\"\\nSample of filtered data:\")\nprint(filtered_df.head())",
    "execution_output": "Loaded payments data. Total rows: 138236\nFiltered for merchant 'Martinis_Fine_Steakhouse' and year 2023.\nResulting rows: 13805\n\nSample of filtered data:\n    psp_reference                  merchant card_scheme  year  hour_of_day  minute_of_hour  day_of_year  is_credit  eur_amount ip_country issuing_country device_type              ip_address           email_address             card_number shopper_interaction  card_bin  has_fraudulent_dispute  is_refused_by_adyen aci acquirer_country\n13    39321493661  Martinis_Fine_Steakhouse  GlobalCard  2023            9              48           42       True       29.47         FR              FR       Linux  0LG7KSVCKOxMGDkgRElCZA  tCUsaB-FqRo7u9PBFRL9OA  Dqk1EsUqVh-mzFQdrg3Wzw           Ecommerce      4916                   False                False   D               FR\n50    24796561934  Martinis_Fine_Steakhouse  GlobalCard  2023           15              15          131       True      102.88         GR              GR       Other  9icJ_wdB1s4wFeTUX37qQQ  xFJ2x8xsl0qrnp83ZtTv8w  LHZKE1No_msVwVxAT6lZIA           Ecommerce      4556                   False                False   D               FR\n55    21702732737  Martinis_Fine_Steakhouse      NexPay  2023           19               3          291       True       45.11         BE              BE       Other  x8fwfbBnI_i1bQsm1nn_uw                     NaN  0IZ6uTwI3SiPFBgBl2GcRQ                 POS      4916                   False                False   B               FR\n58    71209492949  Martinis_Fine_Steakhouse      NexPay  2023           17              20          226       True       94.46         GR              GR     Android  3nc_L6rj0rcnMCn49Q3Biw  Ln9hAIt17mMS-xXpmBlGpw  KaPbqryvRCuVLz5HCmfwBA           Ecommerce      4556                   False                False   D               FR\n76    80211788576  Martinis_Fine_Steakhouse  GlobalCard  2023           22              11           30       True       62.96         BE              BE       Other                     NaN  eDaA7wLzXDzyEKGlhWZ8wA  Ur-i7ri9uNmV_mnQFB6Gug                 POS      4622                   False                False   A               FR\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.1,
    "plan_snapshot": [
      "Load the `payments.csv` file and filter the data to include only transactions for the merchant \"Martinis_Fine_Steakhouse\" in the year 2023."
    ]
  },
  {
    "round": 2,
    "plan_steps": 2,
    "code_length": 9780,
    "code": "import pandas as pd\nimport json\nimport numpy as np\n\n# ---------------------------------------------------------\n# HELPER FUNCTIONS\n# ---------------------------------------------------------\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        return float(v)\n    return float(value)\n\ndef parse_range(range_str):\n    \"\"\"\n    Parses a range string like '100k-1m' or '7.7%-8.3%' into a tuple (min, max).\n    Returns (None, None) if parsing fails or input is None.\n    \"\"\"\n    if not isinstance(range_str, str):\n        return None, None\n    \n    # Handle k/m suffixes\n    def parse_val(v):\n        v = v.lower().strip()\n        mult = 1\n        if 'k' in v:\n            mult = 1000\n            v = v.replace('k', '')\n        elif 'm' in v:\n            mult = 1_000_000\n            v = v.replace('m', '')\n        \n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        return float(v) * mult\n\n    try:\n        if '-' in range_str:\n            parts = range_str.split('-')\n            return parse_val(parts[0]), parse_val(parts[1])\n        elif '>' in range_str:\n            val = parse_val(range_str.replace('>', ''))\n            return val, float('inf')\n        elif '<' in range_str:\n            val = parse_val(range_str.replace('<', ''))\n            return float('-inf'), val\n        else:\n            # Exact value or manual handling\n            val = parse_val(range_str)\n            return val, val\n    except:\n        return None, None\n\ndef get_month_from_day(day_of_year):\n    \"\"\"Returns month (1-12) from day of year (1-365).\"\"\"\n    # Days in months for non-leap year (2023)\n    days_in_months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n    cumulative_days = [0] + list(np.cumsum(days_in_months))\n    \n    for i, cutoff in enumerate(cumulative_days[1:], 1):\n        if day_of_year <= cutoff:\n            return i\n    return 12 # Fallback\n\ndef match_fee_rule(tx_ctx, rule):\n    \"\"\"\n    Checks if a transaction context matches a fee rule.\n    tx_ctx: dict containing transaction details + monthly stats\n    rule: dict from fees.json\n    \"\"\"\n    # 1. Card Scheme (Exact match)\n    if rule.get('card_scheme') and rule['card_scheme'] != tx_ctx['card_scheme']:\n        return False\n\n    # 2. Account Type (List match - wildcard [] matches all)\n    if rule.get('account_type'):\n        if tx_ctx['account_type'] not in rule['account_type']:\n            return False\n\n    # 3. Capture Delay (Exact match - wildcard null matches all)\n    if rule.get('capture_delay') is not None:\n        if rule['capture_delay'] != tx_ctx['capture_delay']:\n            # Handle special cases like '>5' if necessary, but data seems to have discrete strings\n            # If rule is '>5' and tx is '7', we might need logic.\n            # Checking unique values: rule values are '3-5', '>5', '<3', 'immediate', 'manual'.\n            # Tx values are '1', '2', '7', 'immediate', 'manual'.\n            rd = rule['capture_delay']\n            td = str(tx_ctx['capture_delay'])\n            \n            match = False\n            if rd == td:\n                match = True\n            elif rd == '>5':\n                try:\n                    if float(td) > 5: match = True\n                except: pass\n            elif rd == '<3':\n                try:\n                    if float(td) < 3: match = True\n                except: pass\n            elif rd == '3-5':\n                try:\n                    if 3 <= float(td) <= 5: match = True\n                except: pass\n            \n            if not match:\n                return False\n\n    # 4. Merchant Category Code (List match - wildcard [] matches all)\n    if rule.get('merchant_category_code'):\n        if tx_ctx['mcc'] not in rule['merchant_category_code']:\n            return False\n\n    # 5. Is Credit (Exact match - wildcard null matches all)\n    if rule.get('is_credit') is not None:\n        if rule['is_credit'] != tx_ctx['is_credit']:\n            return False\n\n    # 6. ACI (List match - wildcard [] matches all)\n    if rule.get('aci'):\n        if tx_ctx['aci'] not in rule['aci']:\n            return False\n\n    # 7. Intracountry (Exact match - wildcard null matches all)\n    if rule.get('intracountry') is not None:\n        # Rule uses 0.0/1.0/None or boolean?\n        # JSON sample shows 0.0, 1.0.\n        # tx_ctx['intracountry'] is boolean.\n        rule_intra = bool(rule['intracountry'])\n        if rule_intra != tx_ctx['intracountry']:\n            return False\n\n    # 8. Monthly Volume (Range match - wildcard null matches all)\n    if rule.get('monthly_volume'):\n        min_v, max_v = parse_range(rule['monthly_volume'])\n        if min_v is not None:\n            vol = tx_ctx['monthly_volume']\n            if not (min_v <= vol <= max_v):\n                return False\n\n    # 9. Monthly Fraud Level (Range match - wildcard null matches all)\n    if rule.get('monthly_fraud_level'):\n        min_f, max_f = parse_range(rule['monthly_fraud_level'])\n        if min_f is not None:\n            fraud = tx_ctx['monthly_fraud_rate']\n            if not (min_f <= fraud <= max_f):\n                return False\n\n    return True\n\ndef calculate_fee_amount(amount, rule):\n    \"\"\"Calculates fee based on fixed amount and rate.\"\"\"\n    fixed = rule.get('fixed_amount', 0)\n    rate = rule.get('rate', 0)\n    # Fee = fixed + (rate * amount / 10000)\n    return fixed + (rate * amount / 10000)\n\n# ---------------------------------------------------------\n# MAIN EXECUTION\n# ---------------------------------------------------------\n\n# File paths\npayments_path = '/output/chunk5/data/context/payments.csv'\nfees_path = '/output/chunk5/data/context/fees.json'\nmerchant_data_path = '/output/chunk5/data/context/merchant_data.json'\n\n# 1. Load Data\nprint(\"Loading data...\")\ndf_payments = pd.read_csv(payments_path)\nwith open(fees_path, 'r') as f:\n    fees_data = json.load(f)\nwith open(merchant_data_path, 'r') as f:\n    merchant_data_list = json.load(f)\n\n# 2. Filter for Merchant and Year\ntarget_merchant = \"Martinis_Fine_Steakhouse\"\ntarget_year = 2023\nprint(f\"Filtering for {target_merchant} in {target_year}...\")\n\ndf_tx = df_payments[\n    (df_payments['merchant'] == target_merchant) & \n    (df_payments['year'] == target_year)\n].copy()\n\nif df_tx.empty:\n    print(\"No transactions found.\")\n    exit()\n\n# 3. Get Merchant Metadata\nmerchant_info = next((m for m in merchant_data_list if m['merchant'] == target_merchant), None)\nif not merchant_info:\n    print(\"Merchant info not found.\")\n    exit()\n\noriginal_mcc = merchant_info['merchant_category_code']\naccount_type = merchant_info['account_type']\ncapture_delay = merchant_info['capture_delay']\nnew_mcc = 5999\n\nprint(f\"Merchant Metadata: Original MCC={original_mcc}, New MCC={new_mcc}, Account Type={account_type}, Capture Delay={capture_delay}\")\n\n# 4. Calculate Monthly Stats\n# Add month column\ndf_tx['month'] = df_tx['day_of_year'].apply(get_month_from_day)\n\n# Group by month to get volume and fraud stats\nmonthly_stats = {}\nfor month in range(1, 13):\n    month_txs = df_tx[df_tx['month'] == month]\n    if month_txs.empty:\n        monthly_stats[month] = {'volume': 0, 'fraud_rate': 0}\n        continue\n    \n    total_vol = month_txs['eur_amount'].sum()\n    \n    # Fraud volume: sum of amounts where has_fraudulent_dispute is True\n    # Note: Manual says \"Fraud is defined as the ratio of fraudulent volume over total volume.\"\n    fraud_vol = month_txs[month_txs['has_fraudulent_dispute']]['eur_amount'].sum()\n    \n    fraud_rate = fraud_vol / total_vol if total_vol > 0 else 0\n    \n    monthly_stats[month] = {\n        'volume': total_vol,\n        'fraud_rate': fraud_rate\n    }\n\n# 5. Calculate Fees and Delta\ntotal_delta = 0.0\nprocessed_count = 0\n\n# Pre-process fees to avoid repeated parsing if possible, but for now we use the helper\n# Optimization: Sort fees? No, just iterate.\n\nprint(\"Calculating fee delta...\")\n\nfor idx, row in df_tx.iterrows():\n    # Build context\n    month = row['month']\n    stats = monthly_stats[month]\n    \n    # Intracountry: Issuer == Acquirer\n    is_intracountry = (row['issuing_country'] == row['acquirer_country'])\n    \n    base_ctx = {\n        'card_scheme': row['card_scheme'],\n        'account_type': account_type,\n        'capture_delay': capture_delay,\n        'is_credit': row['is_credit'],\n        'aci': row['aci'],\n        'intracountry': is_intracountry,\n        'monthly_volume': stats['volume'],\n        'monthly_fraud_rate': stats['fraud_rate']\n    }\n    \n    # --- Scenario 1: Original MCC ---\n    ctx_original = base_ctx.copy()\n    ctx_original['mcc'] = original_mcc\n    \n    fee_original = 0\n    found_orig = False\n    for rule in fees_data:\n        if match_fee_rule(ctx_original, rule):\n            fee_original = calculate_fee_amount(row['eur_amount'], rule)\n            found_orig = True\n            break\n            \n    # --- Scenario 2: New MCC ---\n    ctx_new = base_ctx.copy()\n    ctx_new['mcc'] = new_mcc\n    \n    fee_new = 0\n    found_new = False\n    for rule in fees_data:\n        if match_fee_rule(ctx_new, rule):\n            fee_new = calculate_fee_amount(row['eur_amount'], rule)\n            found_new = True\n            break\n    \n    # Calculate delta for this transaction\n    # If a rule isn't found, fee is 0 (or we could flag it, but assuming coverage)\n    delta = fee_new - fee_original\n    total_delta += delta\n    \n    processed_count += 1\n\nprint(f\"Processed {processed_count} transactions.\")\nprint(f\"Total Fee Delta: {total_delta:.14f}\")",
    "execution_output": "Loading data...\nFiltering for Martinis_Fine_Steakhouse in 2023...\nMerchant Metadata: Original MCC=5812, New MCC=5999, Account Type=H, Capture Delay=immediate\nCalculating fee delta...\nProcessed 13805 transactions.\nTotal Fee Delta: 2692.24019699999053\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.15000000000000002,
    "plan_snapshot": [
      "Load the `payments.csv` file and filter the data to include only transactions for the merchant \"Martinis_Fine_Steakhouse\" in the year 2023.",
      "Load `merchant_data.json` to get the original MCC, account type, and capture delay for \"Martinis_Fine_Steakhouse\", and load `fees.json`. Then, using the filtered payments data, calculate the monthly total volume and monthly fraud rate (fraudulent volume / total volume) for each month to prepare for fee calculation."
    ]
  }
]