[
  {
    "round": 1,
    "plan_steps": 1,
    "code_length": 2824,
    "code": "# Helper functions for robust data processing\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n        # Range handling (e.g., \"50-60\") - return mean\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        return float(v)\n    return float(value)\n\ndef safe_get(df, column, default=None):\n    \"\"\"Safely get column from DataFrame, return default if not exists.\"\"\"\n    if isinstance(df, dict):\n        return df.get(column, default)\n    elif hasattr(df, 'columns') and column in df.columns:\n        return df[column]\n    return default\n\ndef is_not_empty(array):\n    \"\"\"Check if array/list is not empty. Handles numpy arrays safely.\"\"\"\n    if array is None:\n        return False\n    if hasattr(array, 'size'):  # numpy array\n        return array.size > 0\n    try:\n        return len(array) > 0\n    except TypeError:\n        return False\n\ndef safe_index(array, idx, default=None):\n    \"\"\"Safely get array element at index, return default if out of bounds.\"\"\"\n    try:\n        if 0 <= idx < len(array):\n            return array[idx]\n        return default\n    except (IndexError, TypeError, AttributeError):\n        return default\n\n\nimport pandas as pd\n\n# Set file path\nfile_path = '/output/chunk5/data/context/payments.csv'\n\n# Load the payments data\nprint(f\"Loading {file_path}...\")\ndf = pd.read_csv(file_path)\n\n# Define filter criteria\ntarget_merchant = 'Martinis_Fine_Steakhouse'\ntarget_year = 2023\ntarget_day = 100\n\n# Filter the DataFrame\nfiltered_df = df[\n    (df['merchant'] == target_merchant) &\n    (df['year'] == target_year) &\n    (df['day_of_year'] == target_day)\n]\n\n# Output the results\nprint(f\"Total rows in dataset: {len(df)}\")\nprint(f\"Rows matching Merchant '{target_merchant}', Year {target_year}, Day {target_day}: {len(filtered_df)}\")\n\nprint(\"\\nFirst 5 rows of filtered data:\")\nprint(filtered_df.head())\n\n# Print unique combinations of columns relevant to fee calculation to aid next steps\n# Fee rules typically depend on: card_scheme, is_credit, aci, issuing_country, acquirer_country\nfee_relevant_cols = ['card_scheme', 'is_credit', 'aci', 'issuing_country', 'acquirer_country']\nif all(col in filtered_df.columns for col in fee_relevant_cols):\n    print(\"\\nUnique transaction profiles (for fee matching):\")\n    print(filtered_df[fee_relevant_cols].drop_duplicates().to_string(index=False))",
    "execution_output": "Loading /output/chunk5/data/context/payments.csv...\nTotal rows in dataset: 138236\nRows matching Merchant 'Martinis_Fine_Steakhouse', Year 2023, Day 100: 41\n\nFirst 5 rows of filtered data:\n       psp_reference                  merchant   card_scheme  year  hour_of_day  minute_of_hour  day_of_year  is_credit  eur_amount ip_country issuing_country device_type              ip_address           email_address             card_number shopper_interaction  card_bin  has_fraudulent_dispute  is_refused_by_adyen aci acquirer_country\n4620     39817478036  Martinis_Fine_Steakhouse        NexPay  2023            6              18          100       True      116.93         NL              NL     Android  FwG7B8DEYQ3p1Toa7I-i4g                     NaN  GVlSpgwvPU-pDbqVwFijbg           Ecommerce      4526                   False                False   D               FR\n6706     50072603720  Martinis_Fine_Steakhouse  TransactPlus  2023            4               1          100       True       36.19         LU              LU       Linux  HCgsbJMzJc3jW8HiAi0MPQ  BeSjL6H-CrBHdMCOKVvexg  dPgLLdlGBiuUqUHkWIJb8g           Ecommerce      4891                   False                False   G               FR\n7569     30110703203  Martinis_Fine_Steakhouse  TransactPlus  2023           10              23          100       True       25.20         BE              NL     Android  pKc2dI7FQB5f1iWG_014Lw  hcWVqcj36hOyikjuYV1Hmg  0xxa__nQXAQWQQ4b_xc0Fg           Ecommerce      4571                    True                False   G               FR\n12137    28303996019  Martinis_Fine_Steakhouse  TransactPlus  2023           19               4          100      False       43.08         BE              BE     Windows  ML29E8P85C-CfKlGWCztog  U6z_4fzb3m8mZjFaipzEUw  w87xtwYCwu-wl7V7g4zKkQ           Ecommerce      4556                   False                False   F               FR\n17944    58989273244  Martinis_Fine_Steakhouse  TransactPlus  2023           13              20          100       True        2.85         ES              ES       Other                     NaN  mluVtlIeHnsVVaq5R8KLFA  OBTV3QcJwsK2t4xr9lBG1w           Ecommerce      4802                   False                False   D               FR\n\nUnique transaction profiles (for fee matching):\n card_scheme  is_credit aci issuing_country acquirer_country\n      NexPay       True   D              NL               FR\nTransactPlus       True   G              LU               FR\nTransactPlus       True   G              NL               FR\nTransactPlus      False   F              BE               FR\nTransactPlus       True   D              ES               FR\n  GlobalCard      False   D              NL               FR\n      NexPay       True   D              BE               FR\n  GlobalCard       True   D              BE               FR\n      NexPay       True   G              SE               FR\n  GlobalCard      False   A              NL               FR\n  GlobalCard      False   F              FR               FR\n  GlobalCard      False   F              SE               FR\n SwiftCharge      False   A              IT               FR\nTransactPlus       True   G              IT               FR\n  GlobalCard       True   A              BE               FR\nTransactPlus       True   D              NL               FR\n  GlobalCard      False   F              GR               FR\n  GlobalCard       True   G              FR               FR\n  GlobalCard       True   G              BE               FR\n  GlobalCard       True   D              NL               FR\n SwiftCharge       True   G              IT               FR\n      NexPay       True   A              NL               FR\n  GlobalCard       True   G              NL               FR\n  GlobalCard       True   D              IT               FR\n      NexPay      False   G              BE               FR\nTransactPlus       True   D              BE               FR\n  GlobalCard       True   D              SE               FR\n  GlobalCard       True   D              GR               FR\n      NexPay       True   D              IT               FR\n      NexPay      False   B              IT               FR\n  GlobalCard       True   D              ES               FR\n SwiftCharge       True   B              ES               FR\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.1,
    "plan_snapshot": [
      "Load the `payments.csv` file and filter the data to include only rows where the `merchant` is 'Martinis_Fine_Steakhouse', the `year` is 2023, and the `day_of_year` is 100."
    ]
  },
  {
    "round": 2,
    "plan_steps": 2,
    "code_length": 8637,
    "code": "import pandas as pd\nimport json\nimport numpy as np\n\n# --- Helper Functions ---\n\ndef coerce_to_float(value):\n    \"\"\"Convert string with %, $, commas, k, m to float. Handles common formats.\"\"\"\n    if isinstance(value, (int, float)):\n        return float(value)\n    if isinstance(value, str):\n        v = value.strip().replace(',', '').replace('\u20ac', '').replace('$', '')\n        v = v.lstrip('><\u2264\u2265')  # Remove comparison operators\n        \n        # Handle percentages\n        if '%' in v:\n            return float(v.replace('%', '')) / 100\n            \n        # Handle k (thousands) and m (millions)\n        lower_v = v.lower()\n        if 'k' in lower_v:\n            return float(lower_v.replace('k', '')) * 1_000\n        if 'm' in lower_v:\n            return float(lower_v.replace('m', '')) * 1_000_000\n            \n        # Range handling (e.g., \"50-60\") - return mean (fallback, though parse_range is preferred for rules)\n        if '-' in v and len(v.split('-')) == 2:\n            try:\n                parts = v.split('-')\n                return (float(parts[0]) + float(parts[1])) / 2\n            except:\n                pass\n        try:\n            return float(v)\n        except ValueError:\n            return 0.0\n    return 0.0\n\ndef parse_range(range_str):\n    \"\"\"Parses strings like '100k-1m', '7.7%-8.3%', '>5', '<3' into (min, max).\"\"\"\n    if not isinstance(range_str, str):\n        return None, None\n    \n    s = range_str.lower().strip()\n    \n    # Helper to parse individual values using coerce_to_float\n    def parse_val(v):\n        return coerce_to_float(v)\n\n    if '-' in s:\n        parts = s.split('-')\n        return parse_val(parts[0]), parse_val(parts[1])\n    elif '>' in s:\n        val = parse_val(s.replace('>', ''))\n        return val, float('inf')\n    elif '<' in s:\n        val = parse_val(s.replace('<', ''))\n        return float('-inf'), val\n    else:\n        # Exact match treated as range [val, val]\n        val = parse_val(s)\n        return val, val\n\ndef check_capture_delay(merchant_delay, rule_delay):\n    \"\"\"Checks if merchant capture delay matches rule.\"\"\"\n    if rule_delay is None:\n        return True\n    \n    m_delay = str(merchant_delay).lower()\n    r_delay = str(rule_delay).lower()\n    \n    if r_delay == m_delay:\n        return True\n    \n    # Map merchant delay to days for numeric comparison\n    # 'immediate' -> 0 days\n    delay_map = {\n        'immediate': 0,\n        'manual': 999, # Treated as very high number for > comparisons\n        '1': 1, '2': 2, '7': 7\n    }\n    \n    m_days = delay_map.get(m_delay)\n    if m_days is None:\n        try:\n            m_days = float(m_delay)\n        except:\n            return False # Unknown format\n            \n    # Handle rule ranges\n    if '-' in r_delay:\n        min_d, max_d = parse_range(r_delay)\n        return min_d <= m_days <= max_d\n    elif '>' in r_delay:\n        val = coerce_to_float(r_delay)\n        return m_days > val\n    elif '<' in r_delay:\n        val = coerce_to_float(r_delay)\n        return m_days < val\n    \n    return False\n\ndef match_fee_rule(tx_context, rule):\n    \"\"\"\n    Matches a transaction context against a fee rule.\n    tx_context must contain:\n    - card_scheme, account_type, merchant_category_code, capture_delay\n    - monthly_volume, monthly_fraud_rate\n    - is_credit, aci, intracountry\n    \"\"\"\n    \n    # 1. Card Scheme (Exact match)\n    if rule.get('card_scheme') and rule['card_scheme'] != tx_context['card_scheme']:\n        return False\n        \n    # 2. Account Type (List match - rule['account_type'] is a list)\n    if rule.get('account_type'): # If list is not empty\n        if tx_context['account_type'] not in rule['account_type']:\n            return False\n            \n    # 3. Merchant Category Code (List match)\n    if rule.get('merchant_category_code'): # If list is not empty\n        if tx_context['merchant_category_code'] not in rule['merchant_category_code']:\n            return False\n            \n    # 4. Capture Delay (Complex match)\n    if rule.get('capture_delay'):\n        if not check_capture_delay(tx_context['capture_delay'], rule['capture_delay']):\n            return False\n            \n    # 5. Monthly Volume (Range match)\n    if rule.get('monthly_volume'):\n        min_v, max_v = parse_range(rule['monthly_volume'])\n        if not (min_v <= tx_context['monthly_volume'] <= max_v):\n            return False\n            \n    # 6. Monthly Fraud Level (Range match)\n    if rule.get('monthly_fraud_level'):\n        min_f, max_f = parse_range(rule['monthly_fraud_level'])\n        # Fraud rate in context is float (e.g. 0.08). Range parser handles %.\n        if not (min_f <= tx_context['monthly_fraud_rate'] <= max_f):\n            return False\n            \n    # 7. Is Credit (Bool match)\n    if rule.get('is_credit') is not None:\n        if rule['is_credit'] != tx_context['is_credit']:\n            return False\n            \n    # 8. ACI (List match)\n    if rule.get('aci'): # If list is not empty\n        if tx_context['aci'] not in rule['aci']:\n            return False\n            \n    # 9. Intracountry (Bool match)\n    if rule.get('intracountry') is not None:\n        # rule['intracountry'] might be 0.0/1.0 or boolean in JSON\n        rule_intra = bool(rule['intracountry'])\n        if rule_intra != tx_context['intracountry']:\n            return False\n            \n    return True\n\n# --- Main Execution ---\n\n# Load files\npayments_path = '/output/chunk5/data/context/payments.csv'\nfees_path = '/output/chunk5/data/context/fees.json'\nmerchant_path = '/output/chunk5/data/context/merchant_data.json'\n\nprint(\"Loading data...\")\ndf_payments = pd.read_csv(payments_path)\nwith open(fees_path, 'r') as f:\n    fees_data = json.load(f)\nwith open(merchant_path, 'r') as f:\n    merchant_data_list = json.load(f)\n\n# Target Parameters\ntarget_merchant = 'Martinis_Fine_Steakhouse'\ntarget_day = 100\ntarget_year = 2023\n\n# 1. Get Merchant Metadata\nmerchant_info = next((m for m in merchant_data_list if m['merchant'] == target_merchant), None)\nif not merchant_info:\n    print(f\"Merchant {target_merchant} not found in merchant_data.json\")\n    exit()\n\nprint(f\"Merchant Info: Account Type={merchant_info['account_type']}, MCC={merchant_info['merchant_category_code']}, Capture Delay={merchant_info['capture_delay']}\")\n\n# 2. Calculate Monthly Stats (April 2023)\n# Day 100 falls in April.\n# Jan (31) + Feb (28) + Mar (31) = 90 days.\n# April starts Day 91, ends Day 120 (30 days).\napril_start = 91\napril_end = 120\n\napril_txs = df_payments[\n    (df_payments['merchant'] == target_merchant) &\n    (df_payments['year'] == target_year) &\n    (df_payments['day_of_year'] >= april_start) &\n    (df_payments['day_of_year'] <= april_end)\n]\n\nmonthly_volume = april_txs['eur_amount'].sum()\nfraud_volume = april_txs[april_txs['has_fraudulent_dispute']]['eur_amount'].sum()\nmonthly_fraud_rate = fraud_volume / monthly_volume if monthly_volume > 0 else 0.0\n\nprint(f\"April Stats (Days {april_start}-{april_end}):\")\nprint(f\"  Volume: \u20ac{monthly_volume:,.2f}\")\nprint(f\"  Fraud Rate: {monthly_fraud_rate:.4%}\")\n\n# 3. Get Transactions for Day 100\nday_100_txs = df_payments[\n    (df_payments['merchant'] == target_merchant) &\n    (df_payments['year'] == target_year) &\n    (df_payments['day_of_year'] == target_day)\n]\n\nprint(f\"Transactions on Day {target_day}: {len(day_100_txs)}\")\n\nif len(day_100_txs) == 0:\n    print(\"No transactions found for this day.\")\n    exit()\n\n# 4. Find Applicable Fees\napplicable_fee_ids = set()\n\n# Optimization: Get unique transaction profiles to avoid checking every single row\n# Relevant columns for fee matching: card_scheme, is_credit, aci, issuing_country, acquirer_country\nunique_profiles = day_100_txs[['card_scheme', 'is_credit', 'aci', 'issuing_country', 'acquirer_country']].drop_duplicates()\n\nprint(f\"Unique transaction profiles to check: {len(unique_profiles)}\")\n\nfor _, row in unique_profiles.iterrows():\n    # Build context\n    context = {\n        'card_scheme': row['card_scheme'],\n        'account_type': merchant_info['account_type'],\n        'merchant_category_code': merchant_info['merchant_category_code'],\n        'capture_delay': merchant_info['capture_delay'],\n        'monthly_volume': monthly_volume,\n        'monthly_fraud_rate': monthly_fraud_rate,\n        'is_credit': row['is_credit'],\n        'aci': row['aci'],\n        'intracountry': row['issuing_country'] == row['acquirer_country']\n    }\n    \n    # Check against all rules\n    for rule in fees_data:\n        if match_fee_rule(context, rule):\n            applicable_fee_ids.add(rule['ID'])\n\n# 5. Output\nsorted_ids = sorted(list(applicable_fee_ids))\nprint(f\"Applicable Fee IDs: {', '.join(map(str, sorted_ids))}\")",
    "execution_output": "Loading data...\nMerchant Info: Account Type=H, MCC=5812, Capture Delay=immediate\nApril Stats (Days 91-120):\n  Volume: \u20ac102,916.05\n  Fraud Rate: 9.9154%\nTransactions on Day 100: 41\nUnique transaction profiles to check: 32\nApplicable Fee IDs: 12, 36, 107, 150, 160, 162, 187, 280, 367, 381, 394, 431, 433, 454, 473, 477, 491, 572, 616, 626, 660, 682, 702, 709, 741, 769, 813, 888, 891, 913, 960, 980\n",
    "original_error": null,
    "debugger_used": false,
    "verification": "insufficient",
    "temperature": 0.15000000000000002,
    "plan_snapshot": [
      "Load the `payments.csv` file and filter the data to include only rows where the `merchant` is 'Martinis_Fine_Steakhouse', the `year` is 2023, and the `day_of_year` is 100.",
      "Load `merchant_data.json` to retrieve the `account_type`, `merchant_category_code`, and `capture_delay` for 'Martinis_Fine_Steakhouse'. Then, load `payments.csv` to calculate the merchant's total transaction volume and fraud rate for April 2023 (days 91-120), and finally, load `fees.json` to identify which Fee IDs apply to the transactions from day 100 based on the merchant's attributes, monthly stats, and transaction details (scheme, credit status, ACI, intracountry status)."
    ]
  }
]